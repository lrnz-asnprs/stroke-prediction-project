{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "# https://www.kaggle.com/fedesoriano/stroke-prediction-dataset \n",
    "df = pd.read_csv(\"..\\\\..\\\\data\\\\healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "DecisionTreePip = Pipeline(steps=[ \n",
    "                               ('Scale',StandardScaler()),\n",
    "                               ('DecisionTreeReg',DecisionTreeRegressor(random_state = 42))\n",
    "                              ])\n",
    "\n",
    "X = df[['age','gender','bmi']]\n",
    "X.gender = X.gender.replace({'Male' : 0, 'Female' : 1 , 'Other' : -1}).astype(np.uint8)\n",
    "\n",
    "# create a dataframe containing the missing values of X\n",
    "missing = X[X.bmi.isna()]\n",
    "\n",
    "# remove the missing values from X \n",
    "X = X.dropna()\n",
    "\n",
    "# creates Y by removing bmi from X\n",
    "Y = X.pop('bmi')\n",
    "\n",
    "# fit the pipeline\n",
    "DecisionTreePip.fit(X,Y)\n",
    "\n",
    "# make the prediction \n",
    "predict_bmi = pd.Series(DecisionTreePip.predict(missing[['age', 'gender']]), index = missing.index)\n",
    "df.loc[missing.index, 'bmi'] = predict_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data samples: Original, Oversampled, Undersampled\n",
    "y = df[[\"stroke\"]].copy()\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS SPLIT THE DATA IN TRAIN AND TEST AND THEN OVERSAMPLE/DOWNSAMPLE\n",
    "# see here: https://stackoverflow.com/questions/48805063/balance-classes-in-cross-validation/48810493#48810493 \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True) # Set shuffle to true to have data of both labels in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([\"id\", \"stroke\"], inplace=True, axis=1)\n",
    "X_test.drop([\"id\", \"stroke\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The oversampled/undersampled data will be used for training ONLY! not for testing\n",
    "\n",
    "from src.Resample import undersample_kmeans\n",
    "from src.Resample import oversample\n",
    "\n",
    "df_input = X_train.copy()\n",
    "df_input[\"stroke\"] = y_train\n",
    "\n",
    "# Get over and undersampled data\n",
    "undersampled = undersample_kmeans(df_input)\n",
    "oversampled = oversample(df_input)\n",
    "\n",
    "y_over_train = oversampled[[\"stroke\"]].copy()\n",
    "y_under_train = undersampled[[\"stroke\"]].copy()\n",
    "\n",
    "oversampled.drop(columns=[\"stroke\"], inplace=True)\n",
    "undersampled.drop(columns=[\"stroke\"], inplace=True)\n",
    "\n",
    "X_over_train = oversampled.copy()\n",
    "X_under_train = undersampled.copy()\n",
    "X_under_train = X_under_train[[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"avg_glucose_level\",\"bmi\",\"smoking_status\"]] # Only do this because column order must be same as X_test column order!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    #('impute', SimpleImputer(strategy='median', copy=False)),\n",
    "    ('minmax_scaler', MinMaxScaler(copy=False))\n",
    "])\n",
    "\n",
    "ordinal_pipe = Pipeline([\n",
    "    ('one_hot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "binary_pipe = Pipeline([\n",
    "    ('label_encoder', OrdinalEncoder()),\n",
    "])\n",
    "\n",
    "# two pipelines combined in the column transformer\n",
    "full_transform = ColumnTransformer([\n",
    "    (\"num\", num_pipe, [\"age\", \"avg_glucose_level\", \"bmi\"]),\n",
    "    (\"ord\", ordinal_pipe, [\"gender\", \"work_type\", \"smoking_status\"]),\n",
    "    (\"binary\", binary_pipe, [\"ever_married\", \"Residence_type\"]),\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('trf', full_transform),\n",
    "    # ('knn', KNeighborsClassifier(n_neighbors=7, metric='manhattan'))\n",
    "    # ('svm', SVC(random_state =0))\n",
    "    # ('rforest', RandomForestClassifier(criterion='entropy', n_estimators= 100, random_state= 0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model/pipeline on TRAINING DATA; On either Oversampled, Undersampled, or Original data\n",
    "full_pipeline.fit(X_over_train, y_over_train.values.flatten())\n",
    "\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# KFold cross validation\n",
    "cv = KFold(n_splits=3, random_state=None)\n",
    "accuracies = cross_val_score(estimator = full_pipeline, X = X_over_train, y = y_over_train.values.flatten(), cv = cv) # Set input here! Over, under or original data. Only training data!\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "stroke_recall = cm[1][1]/cm[1].sum()\n",
    "stroke_cases = len(y_test[y_test[\"stroke\"]==1])\n",
    "'''\n",
    "Most important metric we want to look for is the percentage of actual positives that we have identified.\n",
    "This corresponds to HIGH Recall for Stroke True Positive (Recall = Percantage of accurately identified positives)\n",
    "'''\n",
    "print('Confusion Matrix')\n",
    "print(\"There are {} stroke cases in test set\".format(stroke_cases))\n",
    "print(cm)\n",
    "print(\"The Recall of Stroke is: {:.2f} %\".format(stroke_recall*100))\n",
    "print('')\n",
    "print(\"The General Recall is: {:.2f} %\".format(recall*100))\n",
    "print('')\n",
    "print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n",
    "print('')\n",
    "print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print('')\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "print('')\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('')\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('')\n",
    "print('F1: {:.2f}'.format(f1))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "# code inspired from https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/?fbclid=IwAR0g5dlUGF53mbQQ0h9kwV8Ne9-NzYiGjlYwe72GpHbidMEEPAUD2Sgu1yo\n",
    "import sklearn.metrics as metrics\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = full_pipeline.fit_transform(X_over_train, y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do parameter tuning\n",
    "# The GridSearchCV is a library function that is a member of sklearn's model_selection package. It helps to loop through predefined hyperparameters and fit your estimator (model) on your training set. So, in the end, you can select the best parameters from the listed hyperparameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_models = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0]}]), \n",
    "               (KNeighborsClassifier(),[{'n_neighbors':[5,7,8,10], 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n",
    "               (SVC(),[{'C':[0.25,0.5,0.75,1],'kernel':['linear', 'rbf'],'random_state':[0]}]), \n",
    "               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'random_state':[0]}]), \n",
    "               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}]), \n",
    "              (XGBClassifier(), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error']}])]\n",
    "\n",
    "# Transform the input data before fitting it to GridSearch\n",
    "X_transformed = full_pipeline.fit_transform(X_over_train, y_over_train)\n",
    "\n",
    "for i,j in grid_models:\n",
    "    grid = GridSearchCV(estimator = i, param_grid = j, scoring = 'recall', cv = 10)\n",
    "    grid.fit(X_transformed, y_over_train.values.flatten())\n",
    "    best_accuracy = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    print('{}:\\nBest Recall : {:.2f}%'.format(i,best_accuracy*100))\n",
    "    print('Best Parameters : ',best_param)\n",
    "    print('')\n",
    "    print('----------------')\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4024/3953047258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Grid scores on development set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "scores = [\"precision\", \"recall\"]\n",
    "\n",
    "for score in scores:\n",
    "    # Transform the input data before fitting it to GridSearch\n",
    "    X_transformed = full_pipeline.fit_transform(X_over_train, y_over_train)\n",
    "\n",
    "    for i,j in grid_models:\n",
    "        grid = GridSearchCV(estimator = i, param_grid = j, scoring = score, cv = 10)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(grid.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        for mean, std, params in zip(means, stds, grid.cv_results_[\"params\"]):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, grid.predict(X_transformed)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
