{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "# https://www.kaggle.com/fedesoriano/stroke-prediction-dataset \n",
    "df = pd.read_csv(\"..\\\\..\\\\data\\\\healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "DecisionTreePip = Pipeline(steps=[ \n",
    "                               ('Scale',StandardScaler()),\n",
    "                               ('DecisionTreeReg',DecisionTreeRegressor(random_state = 42))\n",
    "                              ])\n",
    "\n",
    "X = df[['age','gender','bmi']]\n",
    "X.gender = X.gender.replace({'Male' : 0, 'Female' : 1 , 'Other' : -1}).astype(np.uint8)\n",
    "\n",
    "# create a dataframe containing the missing values of X\n",
    "missing = X[X.bmi.isna()]\n",
    "\n",
    "# remove the missing values from X \n",
    "X = X.dropna()\n",
    "\n",
    "# creates Y by removing bmi from X\n",
    "Y = X.pop('bmi')\n",
    "\n",
    "# fit the pipeline\n",
    "DecisionTreePip.fit(X,Y)\n",
    "\n",
    "# make the prediction \n",
    "predict_bmi = pd.Series(DecisionTreePip.predict(missing[['age', 'gender']]), index = missing.index)\n",
    "df.loc[missing.index, 'bmi'] = predict_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data samples: Original, Oversampled, Undersampled\n",
    "y = df[[\"stroke\"]].copy()\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS SPLIT THE DATA IN TRAIN AND TEST AND THEN OVERSAMPLE/DOWNSAMPLE\n",
    "# see here: https://stackoverflow.com/questions/48805063/balance-classes-in-cross-validation/48810493#48810493 \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True) # Set shuffle to true to have data of both labels in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "X_train.drop([\"id\", \"stroke\"], inplace=True, axis=1)\n",
    "X_test.drop([\"id\", \"stroke\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset samples per class Counter({0: 3884, 1: 204})\n",
      "Resampled dataset samples per class Counter({0: 204, 1: 204})\n",
      "Original dataset samples per class Counter({0: 3884, 1: 204})\n",
      "Resampled dataset samples per class Counter({0: 3884, 1: 3884})\n"
     ]
    }
   ],
   "source": [
    "# The oversampled/undersampled data will be used for training ONLY! not for testing\n",
    "\n",
    "from src.Resample import undersample_kmeans\n",
    "from src.Resample import oversample\n",
    "\n",
    "df_input = X_train.copy()\n",
    "df_input[\"stroke\"] = y_train\n",
    "\n",
    "# Get over and undersampled data\n",
    "undersampled = undersample_kmeans(df_input)\n",
    "oversampled = oversample(df_input)\n",
    "\n",
    "y_over_train = oversampled[[\"stroke\"]].copy()\n",
    "y_under_train = undersampled[[\"stroke\"]].copy()\n",
    "\n",
    "oversampled.drop(columns=[\"stroke\"], inplace=True)\n",
    "undersampled.drop(columns=[\"stroke\"], inplace=True)\n",
    "\n",
    "X_over_train = oversampled.copy()\n",
    "X_under_train = undersampled.copy()\n",
    "X_under_train = X_under_train[[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"avg_glucose_level\",\"bmi\",\"smoking_status\"]] # Only do this because column order must be same as X_test column order!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    #('impute', SimpleImputer(strategy='median', copy=False)),\n",
    "    ('minmax_scaler', MinMaxScaler(copy=False))\n",
    "])\n",
    "\n",
    "ordinal_pipe = Pipeline([\n",
    "    ('one_hot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "binary_pipe = Pipeline([\n",
    "    ('label_encoder', OrdinalEncoder()),\n",
    "])\n",
    "\n",
    "# two pipelines combined in the column transformer\n",
    "full_transform = ColumnTransformer([\n",
    "    (\"num\", num_pipe, [\"age\", \"avg_glucose_level\", \"bmi\"]),\n",
    "    (\"ord\", ordinal_pipe, [\"gender\", \"work_type\", \"smoking_status\"]),\n",
    "    (\"binary\", binary_pipe, [\"ever_married\", \"Residence_type\"]),\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('trf', full_transform),\n",
    "    ('svm', SVC(random_state =0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "There are 45 stroke cases in test set\n",
      "[[710 267]\n",
      " [ 16  29]]\n",
      "The Recall of Stroke is: 64.44 %\n",
      "\n",
      "Accuracy Score:  0.723091976516634\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 68.95 %\n",
      "\n",
      "Standard Deviation: 10.23 %\n",
      "\n",
      "Precision: 0.10\n",
      "\n",
      "Recall: 0.64\n",
      "\n",
      "F1: 0.17\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fit model/pipeline on TRAINING DATA; On either Oversampled, Undersampled, or Original data\n",
    "full_pipeline.fit(X_over_train, y_over_train.values.flatten())\n",
    "\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# KFold cross validation\n",
    "cv = KFold(n_splits=3, random_state=None)\n",
    "accuracies = cross_val_score(estimator = full_pipeline, X = X_over_train, y = y_over_train.values.flatten(), cv = cv) # Set input here! Over, under or original data. Only training data!\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "stroke_recall = cm[1][1]/cm[1].sum()\n",
    "stroke_cases = len(y_test[y_test[\"stroke\"]==1])\n",
    "'''\n",
    "Most important metric we want to look for is the percentage of actual positives that we have identified.\n",
    "This corresponds to HIGH Recall for Stroke True Positive (Recall = Percantage of accurately identified positives)\n",
    "'''\n",
    "print('Confusion Matrix')\n",
    "print(\"There are {} stroke cases in test set\".format(stroke_cases))\n",
    "print(cm)\n",
    "print(\"The Recall of Stroke is: {:.2f} %\".format(stroke_recall*100))\n",
    "print('')\n",
    "print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n",
    "print('')\n",
    "print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print('')\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "print('')\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('')\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('')\n",
    "print('F1: {:.2f}'.format(f1))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test[\"stroke\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do parameter tuning\n",
    "#   -> grid search!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
